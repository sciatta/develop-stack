# 多线程基础

## 线程创建过程

![concurrency_thread_create](并发编程.assets/concurrency_thread_create.png)



## 线程状态

![concurrency_thread_state](并发编程.assets/concurrency_thread_state.png)



**线程状态**

- `Thread.sleep` <font color=red>当前线程调用此方法，释放CPU，不释放对象锁。作用：给其他线程执行机会的最佳方式。</font>
- `Thread.yield` 当前线程调用此方法，释放CPU，不释放对象锁。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法一定保证yield达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。yield不会导致阻塞。该方法与sleep类似，只是不能由用户指定暂停多长时间。
- `Thread#join` 当前线程里调用其它线程 t 的 join 方法，当前线程进入WAITING/TIMED_WAITING 状态，**当前线程不会释放已经持有的非t对象锁，但可以释放持有的t对象锁**，相当于 `t.wait()`。线程 t 执行完毕或者 millis 时间到，当前线程进入就绪状态。
- `Object#wait` <font color=red>当前线程调用对象的wait方法，当前线程释放对象锁，进入等待队列。</font>依靠 notify/notifyAll 唤醒或者 wait(long timeout) 到timeout时间自动唤醒。
- `Object#notify` 唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll 唤醒在此对象监视器上等待的所有线程。



**中断和异常**

- 线程内部自己处理异常，不溢出到外层。

- 如果线程被 **Object.wait，Thread.join 和 Thread.sleep** 三种方法之一阻塞，此时调用该线程的interrupt() 方法，那么该线程将抛出一个 InterruptedException 中断异常（该线程必须事先预备好处理此异常），从而提早地终结被阻塞状态。如果线程没有被阻塞，这时调用interrupt() 将不起作用，直到执行到 wait()，sleep() 或 join() 时，才马上会抛出InterruptedException。

  **清除中断标志有两种情况：**

  - 遇到wait()，sleep() 或 join() 时，捕获异常，此时的中断标志被清除
  - Thread.interrupted，当中断时返回true，同时清除中断标志

- 如果是计算密集型的操作，可分段处理，每个片段检查状态是否需终止。



## 并发性质

### 原子性

原子操作，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。

Java中的原子操作包括

- 除long和double之外的基本类型的赋值操作

- 所有引用reference的赋值操作

- java.concurrent.Atomic.* 包中所有类的一切操作



### 可见性

对于可见性，Java 提供了 volatile 关键字来保证可见性。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值（**注意JVM的副本机制**）。另外，通过 synchronized 和 Lock 也能够保证可见性，synchronized 和 Lock 能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。

**volatile**

<font color=red>volatile 并不能保证原子性。</font>

- 读取：每次读取都强制从主内存刷数据

- 使用场景：单个线程写；多个线程读（未写之前，读取的是旧值；写之后，可以保证马上读取到新值）；如果是多个写线程，volatile不能保证原子性，需要通过CAS实现

- 原则：能不用就不用，不确定的时候也不用

- 替代方案：Atomic原子操作类（无锁），**乐观锁的实现：volatile+CAS**

- 内存屏障

  ```java
  // 1和2不会重排到3后面
  // 4和5不会重排到3前面
  // 同时可以保证1和2的结果对3、4和5可见
  x=2; // 1
  y=0; // 2
  flag=true;	// 3 flag是volatile
  x=4; // 4
  y=-1 // 5
  ```

  

**synchronized**

同步块比同步方法更高效，尽量缩小同步范围，提高并发度。同步块中用于控制同步的对象，尽量用小对象，不使用this。



### 有序性

Java允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。可以通过volatile关键字来保证一定的”有序性“（通过synchronized 和 Lock保证）。

happens-before原则（先行发生原则）：

1. 程序次序规则：一个线程内，按代码先后顺序
2. 锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作
3. Volatile变量规则：对同一个变量的写操作先行发生于后面对这个变量的读操作
4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出A先于C
5. 线程启动规则：Thread对象的start()方法先行与此线程的每一个动作
6. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
7. 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，通过Thread.join()方法（结束阻塞）、Thread.isAlive()的返回值检测到线程已经终止执行
8. 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始



## synchronized

### 对象头

64位HotSpot，对象头占12字节，对象必须以8字节倍数占用内存空间，因此需要4字节补齐

- 对象头12字节，包括：锁信息、分代年龄、GC信息

  - **8字节** MarkWord

    - 含义

      - 0x1234

        - CPU小端模式    34 12	字节从后向前使用（PC）

        - CPU大端模式    12 34

          | 锁状态/gc | Mark Word（64bits）           | -           | -        | -     | 是否偏向锁    | 锁标志位 |
          | --------- | ----------------------------- | ----------- | -------- | ----- | ------------- | -------- |
          | 无锁      | unused 25                     | hashcode 31 | unused 1 | age 4 | biased_lock 1 | lock 2   |
          | 偏向锁    | thread 54                     | epoch 2     | unused 1 | age 4 | biased_lock 1 | lock 2   |
          | 轻量级锁  | ptr_to_lock_record 62         | -           | -        | -     | -             | lock 2   |
          | 重量级锁  | ptr_to_heavyweight_monitor 62 | -           | -        | -     | -             | lock 2   |
          | gc标志    | -                             | -           | -        | -     | -             | lock 2   |

    - 锁晋升

      - 对象创建初始为无锁
      - 当有一个线程访问时，markword设置线程id，状态为偏向锁；如果仍是同一个线程访问锁，则仍可以获得锁
      - 当有第二个线程征用锁时，撤销偏向锁，写入当前线程栈中LockRecord指针，写入成功的获得锁；写入不成功的开始自旋CAS
      - 当竞争激励，自旋（10次或jvm自适应）锁撤销，向OS申请mutex重量级锁，申请成功的获得锁；不成功的进入阻塞队列，释放CPU资源

      | 锁状态   | 锁标志 |
      | -------- | ------ |
      | 无锁     | 001    |
      | 偏向锁   | 101    |
      | 轻量级锁 | 00     |
      | 重量级锁 | 10     |

    - 偏向锁延迟参数

      - `UseBiasedLocking = true` 开启偏向锁
      - `BiasedLockingStartupDelay = 4000` jvm启动后偏向锁延迟4s

      ```shell
      # jvm默认参数
      java -XX:+PrintFlagsInitial -version
      
      # jvm最终参数，可以通过命令行参数覆盖
      java -XX:+PrintFlagsFinal
      ```

    - 锁降级：不支持，当不使用时，GC就会回收

    - 锁消除：StringBuffer是线程安全的，如append方法被synchronized修饰；当在一个方法，StringBuffer作为局部变量多次调用append时，编译器优化将锁消除

    - 锁粗化：方法内多次调用synchronized方法，会粗化为一个synchronized

  - ClassPointer

    - **4字节** 默认开启类型指针压缩 `-XX:+UseCompressedClassPointers`

      ```shell
      java -XX:+PrintCommandLineFlags -version
      
      # -XX:+UseCompressedClassPointers  压缩类型指针
      # -XX:+UseCompressedOops 压缩对象引用指针
      -XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC
      ```

    - 8字节 不压缩



### 实现

- java 代码
  - synchronized修饰
- 字节码
  - monitorenter
  - monitorexit
- 执行过程
  - 锁升级
- 机器码
  - lock+comxchg



## volatile

### 可见性

共享变量对于多线程的可见性由缓存一致性保证，即happens-before。但无法保证原子性。

- **存储器分级**，包括l0寄存器；l1、l2高速缓存各核独有；l3高速缓存多核共享；l4主存；l5磁盘；l6远程文件存储。访问速度寄存器>l1>l2>l3>主存>磁盘>远程文件存储

- **超线程**，一个core包括一个ALU（Arithmetic&logical Unit）和多个PC、registers，这样一个core就可以处理多个线程。如：4C8T

- **缓存一致性协议**（Intel MESI）

  缓存一致性协议给缓存行（cache line 通常为64字节）定义了4个状态：独占（exclusive）、共享（share）、修改（modified）、失效（invalid），用来描述该缓存行是否被多处理器共享、是否修改。所以缓存一致性协议也称MESI协议。

  - 独占（exclusive）：仅当前处理器拥有该缓存行，并且没有修改过，是最新的值。
  - 共享（share）：有多个处理器拥有该缓存行，每个处理器都没有修改过缓存，是最新的值。
  - 修改（modified）：仅当前处理器拥有该缓存行，并且缓存行被修改过了，**一定时间内会写回主存，回写成功状态会变为S**。
  - 失效（invalid）：缓存行被其他处理器修改过，该值不是最新的值，需要读取主存上最新的值。

  协议协作如下：

  - 一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的数据写回主存。
  - 一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。
  - 一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S。
  - 当CPU需要读取数据时，如果其缓存行的状态是I的，则需要从内存中读取，并把自己状态变成S，如果不是I，则可以直接读取缓存中的值，但在此之前，必须要等待其他CPU的监听结果，如其他CPU也有该数据的缓存且状态是M，则需要等待其把缓存更新到内存之后，再读取。
  - 当CPU需要写数据时，只有在其缓存行是M或者E的时候才能执行，否则需要发出特殊的RFO指令(Read Or Ownership，这是一种总线事务)，通知其他CPU置缓存无效(I)，这种情况下性能开销是相对较大的。在写入完成后，修改其缓存状态为M。

- **缓存行**（cache line）是缓存的基本单位。在读取指令时，按缓存行读取，即一次读取64字节。如果两个线程同时读写一个缓存行的不同数据，根据MESI协议，会互相通知对方缓冲失效，从主存读取最新修改数据（伪共享）。性能大大降低。

  - 可以通过缓存行对齐解决这一问题，两个线程修改自己独立的缓存行就可以了，不需要缓存同步数据



### 禁止指令重排序

- **指令重排序**也就是 CPU 对程序指令进行执行的时候，会按照自己制定的顺序，并不是完全严格按照程序代码编写的顺序执行。这样做的原因也是出于性能因素考虑，CPU对一些可以执行的指令先执行可以提供总体的运行效率，而不是让CPU把时间都浪费在停滞等待上面。

- **X86平台内存屏障**

  - lfence，是一种Load Barrier 读屏障
  - sfence，是一种Store Barrier 写屏障
  - mfence，是一种全能型的屏障，具备lfence和sfence的能力
  - Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。它后面可以跟ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG等指令。

  内存屏障有两个能力

  - 阻止屏障两边的指令重排序
  - 刷新处理器缓存

  Lock前缀实现了类似的能力，它先对总线和缓存加锁，然后执行后面的指令，最后释放锁后会把高速缓存中的数据刷新回主内存。在Lock锁住总线的时候，其他CPU的读写请求都会被阻塞，直到锁释放。不同硬件实现内存屏障的方式不同，Java内存模型屏蔽了这种底层硬件平台的差异，由JVM来为不同的平台生成相应的机器码。java中的关键字volatile其实是一种lock屏障，lock本身不是内存屏障，但是它能完成类似于内存屏障的功能（**没有使用fence，使用的是lock，为了保证可移植性**）。

  <font color=red>也就是说增加了内存屏障过后，就是在操作变量之前，能够看到在主存中的最新值，操作变量之后，可以刷新cpu的高速缓存。</font>

- **java内存屏障**

  - 对Load Barrier来说，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据；
  - 对Store Barrier来说，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存。

  java的内存屏障通常所谓的四种即 `LoadLoad`, `StoreStore`, `LoadStore`, `StoreLoad` 实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。

  - LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。

  - StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。

  - LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。

  - StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。**它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能**

- **volatile内存屏障**

  - 在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障
  - 在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障

- **单例模式DCL（double check lock）**，将单例实例修饰为volatile，因为对象的创建过程不是原子的，所以可能会出现指令重排序。导致线程获取到半初始化的单例对象，从而影响业务逻辑



### 实现

- java 代码
  - volatile修饰
- 字节码
  - flags: ACC_VOLATILE
- jvm规范
  - 内存屏障
- 机器码
  - lock+add



## ThreadLocal

### OOM

ThreadLocal的作用是提供线程内的**局部变量**安全快速访问，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。<font color=red>即提供线程内部的局部变量，在本线程内随时随地可取，隔离其他线程</font>。

- 线程本地变量
- 场景：每个线程一个副本
- <font color=red>不改方法签名静默传参</font>。可以看做是 Context 模式，减少显式传递参数
- **及时进行清理**，防止内存泄漏



若ThreadLocal保存线程和局部变量的映射关系，在写入数据时需要解决多线程冲突问题，加锁或CAS，这样会降低性能。ThreadLocal反其道而行之，ThreadLocal只是作为访问Thread内部局部变量的入口，局部变量和ThreadLocal的映射关系则保存在Thread内部，这样保证ThreadLocal本身是<font color=red>线程安全</font>的。

![concurrency_threadlocal](并发编程.assets/concurrency_threadlocal.png)

- Thread内部维护了一个ThreadLocalMap，其key是一个WeakReference对象，引用的实际对象是ThreadLocal，value是实际值的引用
- Entry的key设计为弱引用，是因为Thread本身强引用ThreadLocalMap，而ThreadLocalMap强引用Entry，如果再强引用ThreadLocal的话，若客户端置ThreadLocal为null的话，但ThreadLocal有强引用关系，导致永远都无法GC回收；当设置为弱引用后，ThreadLocal在经历一次GC后，便可回收
- 但Entry的value仍然具有强引用链，并且客户端无法使用ThreadLocalMap清除value，所以在置ThreadLocal为null前，<font color=red>必须显示的调用remove方法</font>，否则value无法被GC回收，导致OOM
- ThreadLocalMap内部维护了一个循环数组，当发生hash冲突时，会检查entry的key是否是null，如果是，会清除挂在下面的本地变量value，可以起到防止一定OOM的情况发生，但无法完全解决



### 引用类型

- 强引用

  - 没有引用的对象，GC会回收

- 软引用

  - 资源不够时，GC会回收软引用的对象

  - 常用作缓存，兼顾时间和空间

- 弱引用

  - GC看到弱引用对象就会回收

  - 一般用于引用客户端创建的实例，如：ThreadLocal

- 虚引用

  - GC看到虚引用对象就会回收，永远无法获取到引用的对象，唯一的作用就是**引用的对象GC回收前，会将虚引用放到队列并通知客户端进行处理**；其他的引用类型是回收之后，放到队列中
  - NIO对直接内存的管理，引用本身在堆中，可以由JVM管理，但其引用的非堆空间，需要收到GC通知后，虚引用绑定的队列取出虚引用实例作特殊回收处理



# JUC基础

## 锁机制类

### 问题

synchronized 加锁；wait / notify 解锁/加锁

1. 同步块的阻塞无法中断（不能 Interruptibly） 
2. 同步块的阻塞无法控制超时（无法自动解锁）
3. 同步块无法异步处理锁（即不能立即知道是否可以拿到锁）
4. 同步块无法根据条件灵活的加锁解锁（即只能跟同步块范围一致）



### Lock更自由的锁

1. 使用方式灵活可控

   - 基于条件使用锁

   - 锁有超时时间

   - 可以异步获取锁

2. 性能开销小

3. 锁工具包: java.util.concurrent.locks



### ReadWriteLock读写锁

ReadWriteLock管理一组锁，分别是一个读锁和一个写锁。<font color=red>写锁（独占锁），在写线程运行的时候，其他的读、写线程阻塞；读锁（共享锁），在没有写锁的时候，多个读线程可以同时持有读锁。通过锁分离，提高并发性</font>。所有读写锁的实现必须确保写操作对读操作的内存影响。每次只能有一个写线程，但是同时可以有多个线程并发地读数据。

<font color=red>ReadWriteLock 适用于读多写少的并发情况</font>。



### Condition

通过 Lock.newCondition()创建。可以看做是 Lock 对象上的信号。类似于 wait/notify，相应api为 await/signal。



### LockSupport锁当前线程

LockSupport 类似于 Thread 类的静态方法，专门用于处理本线程。<font color=red>阻塞当前线程，但不释放锁资源</font>。

unpark需要由其他线程调用，并且以被park的线程作为参数。因为一个被park的线程，无法自己唤醒自己，所以需要其他线程来唤醒。

- park默认情况下是没有许可的，所以直接调用park的话，会阻塞；可以提前调用unpark，归还许可，此时park的话，消费许可，不会阻塞立即返回
- park阻塞的时候，如果向这个线程发起中断，这个线程被唤醒，但是不会抛出异常



### 锁的区分

- 可重入锁：同一线程可以重复获取同一个锁，**同一个线程可以进入加锁的不同方法**
- 公平锁 / 非公平锁
  - 没有获得锁的线程进入等待队列，等待时间久的线程（先入队列）优先获得锁，称为公平锁。**线程会查看等待队列**。
  - 即使队列中有等待获得锁的线程，新的待获取锁的线程也有机会获得锁，称为非公平锁。**线程不会查看等待队列，直接上去抢占资源，抢不到才会入队**
- 乐观锁 / 悲观锁
  - 先访问资源，若已被修改，则自旋重试。不上锁，称为乐观锁
  - 访问资源之前，先上锁，其他线程无法访问。修改后再释放锁，称为悲观锁



### 最佳实践

1. 永远只在更新对象的成员变量时加锁
2. 永远只在访问可变的成员变量时加锁
3. 永远不在调用其他对象的方法时加锁



<font color=red>最小使用锁</font>

1. 降低锁范围：锁定代码的范围/作用域
2. 细分锁粒度：将一个大锁，拆分成多个小锁



## 并发原子类

### 问题

sum++多线程安全问题。对于基础数据类型的并发补充实现，线程安全。



### Atomic工具类

1. java.util.concurrent.atomic

2. AtomicInteger

3. 无锁技术的底层实现

   1. volatile 保证读写操作都可见（注意不保证原子）
   2. 使用 CAS 指令，作为乐观锁实现，通过自旋重试保证写入。
      - Unsafe API - Compare-And-Swap
      - CPU 硬件指令支持: CAS 指令
        - LOCK_IF_MP
        - cmpxchg
      - **ABA问题：通过加入version解决**

4. 有锁 or 无锁？

   CAS 本质上没有使用锁。并发压力跟锁性能的关系：

   - 压力非常小，性能本身要求就不高，有锁、无锁差别不明显
   - 压力一般的情况下，无锁更快，大部分都一次写入

   - <font color=red>压力非常大时（执行时间长、并发高），自旋导致重试过多，资源消耗很大。有锁较好。</font>



### LongAdder

通过分段思想对原子类AtomicLong改进

1. AtomicInteger 和 AtomicLong 里的 value 是所有线程竞争读写的热点数据
2. 将单个 value 拆分成跟线程一样多的数组 Cell[]
3. 每个线程写自己的 Cell[i]++，最后对数组求和

多路归并思想

- 快排
- G1GC
- ConcurrentHashMap
- MapReduce



## 信号量工具类

### 问题

多个线程间的协作，可以通过 wait/notify、Lock/Condition，但如果需要更为精细化的控制，则实现起来非常复杂还容易出错。

更复杂的应用场景

- 我们需要控制实际并发访问资源的并发数量
- 我们需要多个线程在某个时间同时开始运行
- 我们需要指定数量线程到达某个状态再继续处理



### AQS

AbstractQueuedSynchronizer，即队列同步器。它是构建锁或者其他同步组件的基础（如Semaphore、CountDownLatch、ReentrantLock、ReentrantReadWriteLock），是JUC并发包中的核心基础组件。

- AbstractQueuedSynchronizer：抽象队列式的同步器
- 两种资源共享方式：独占 OR 共享，子类负责实现公平 OR 非公平



### Semaphore信号量

- 准入数量 N（限流）
- N =1 则等价于独占锁

Semaphore的本质是共享锁，限制同时访问锁的数量。



### CountdownLatch

场景：Master 线程等待 Worker 线程把任务执行完

类似于fork/join的多线程处理，master线程阻塞，等待多个slave线程并发执行完成后，再汇总统计结果。



### CyclicBarrier

场景：任务执行到一定阶段，等待其他任务对齐，对齐之后一起向前运行

与CountdownLatch区别

- CountdownLatch递减；CyclicBarrier递增
- CountdownLatch在主线程通过await阻塞，其他线程countDown，类似join；CyclicBarrier不在主线程阻塞，而是在**每个**被调用线程处通过await阻塞，等待所有线程对齐（满足parties），然后所有线程同时退出阻塞状态继续执行
  - CyclicBarrier可以在任务前阻塞，然后满足限制线程数后一起向前执行；也可以在任务结束后，满足限制线程数后一起向前执行
  - CountdownLatch一般用于子线程任务完成后对齐
- 对于从阻塞状态恢复的线程，CountdownLatch不可重复利用，而CyclicBarrier可以reset重复利用（循环屏障）



## 线程池

线程池从功能上看，就是一个<font color=red>任务执行器</font>

### Excutor

执行者，顶层接口



### ExcutorService

接口 API

- shutdown()：停止接收新任务，原来的任务继续执行

- shutdownNow()：停止接收新任务，原来的任务停止执行

- awaitTermination(long timeOut, TimeUnit unit)：当前线程阻塞
- submit：有返回值，用 Future 封装，异常可以被catch
- execute方法：无返回值，无法cache异常



### ThreadFactory

线程工厂



### Excutors

工具类

- newSingleThreadExecutor
  创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。

- newFixedThreadPool
  创建固定大小的线程池。每次提交一个任务就创建一个线程，<font color=red>先保证核心线程数处理任务，多余的任务置入队列，再多余的任务则新增线程处理直到达到最大线程数，再多余的任务可以根据丢弃策略处理。算法同时满足CPU密集和IO密集型任务处理。</font>

  线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。

  - **缺点**
    - 线程池一旦达到最大，就会保持不变，即使在负载下降后，仍会保持大量空闲线程（核心线程数=最大线程数）
    - 核心线程数超过后，会置入队列，但队列大小几乎无限（Integer.MAX_VALUE），导致任务无法及时响应
  - CPU密集
    - 超过核心线程数，任务置入队列，因为是cpu密集型任务，可以保证队列中的任务可以快速处理完成，而不需要额外创建过多的线程数处理任务，过多的线程，反而会消耗系统资源，上下文切换也会给性能带来损耗
    - 最大核心数设置为N或N+1
  - IO密集型
    - 由队列先缓存一部分任务等待IO，若超过队列限制，则增量线程到最大线程数
    - 最大核心数设置为2N或2(N+1)

- newCachedThreadPool
  创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。

  - 适用于大量可以快速处理的小任务，提高并发度。
  - **缺点**
    - 核心线程数是0，最大线程数几乎无限（Integer.MAX_VALUE），当有大量任务时，很有可能会超过操作系统的最大线程数OutOfMemoryError：Unable to create new native thread
  
- newScheduledThreadPool
  创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。
  
  - `schedule` 延迟执行一次性任务
  - `scheduleAtFixedRate` 延迟+定时执行任务，period：本次开始时间-上次开始时间，**以开始时间对齐，不考虑任务执行时间**
  - `scheduleWithFixedDelay` 延迟+定时执行任务，period：本次开始时间-上次结束时间，**考虑任务执行的时间，如果任务执行时间长，则下一次的开始时间也会相应推迟，关注两次任务执行的时间间隔**
  - **缺点**
    - 如果是周期性执行任务，队列中的任务不会回收，同时又不停的新产生任务的话，会出现OOM



### ThreadPoolExecutor

具体线程池实现类

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler)
```

**线程池参数**

- corePoolSize 线程池中线程的数量，即使是空闲状态
- maximumPoolSize 线程池中允许的最大线程数量
- keepAliveTime 当线程池中的线程数量超过了corePoolSize，多余的线程在结束前等待任务的最大时间；超过存活时间，则被回收
- unit keepAliveTime参数的时间单位
- BlockingQueue 缓存队列
  1. ArrayBlockingQueue：规定大小的 BlockingQueue，其构造必须指定大小。其所含的对象是 FIFO 顺序排序的
  2. LinkedBlockingQueue：大小不固定的 BlockingQueue，若其构造时指定大小，生成的 BlockingQueue 有大小限制，不指定大小，其大小由 Integer.MAX_VALUE 来决定。其所含的对象是 FIFO 顺序排序的
  3. PriorityBlockingQueue：类似于 LinkedBlockingQueue，但是其所含对象的排序不是 FIFO，而是依据对象的自然顺序或者构造函数的 Comparator 决定
  4. SynchronizedQueue：特殊的 BlockingQueue，对其的操作必须是放和取交替完成
- ThreadFactory 创建自定义新线程
- RejectedExecutionHandler 拒绝策略
  1. ThreadPoolExecutor.AbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常（**默认**）
  2. ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常
  3. ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务
  4. ThreadPoolExecutor.CallerRunsPolicy：由调用线程（提交任务的线程）即线程池所在线程处理该任务，可以卡住新任务申请

**线程池方法**

- `execute(Runnable command)` 方法逻辑

  - 当前线程数小于corePoolSize时，创建工作线程（延迟创建）并运行
  - 当前线程数大于等于corePoolSize时，保存在阻塞队列中
  - 阻塞队列容量满，则继续创建工作线程，直到maximumPoolSize
  - 当线程数大于等于maximumPoolSize时，多余任务执行拒绝策略处理器

  <font color=red>当大于等于corePoolSize时，任务首先保存在阻塞队列中。适用于CPU密集型任务，因为队列中的任务可以被快速获取和执行不至于大量积压任务，并且创建大量的线程没有用，频繁切换线程上下文会导致性能下降。之后，创建工作线程直到满足maximumPoolSize，适用于IO密集型任务，当线程处理IO时可以释放CPU资源，多余的线程可以充分打满CPU提高利用率。</font>

**源码解析**

- 用一个**4字节**的Integer表示线程池运行状态和容量
  - 高3位表示线程池运行状态
    - 111 RUNNING
    - 000 SHUTDOWN
    - 001 STOP
    - 010 TIDYING
    - 011 TERMINATED
  - 低29位表示线程池容量

- 主要逻辑
  - 如果队列没有任务，Worker线程获取任务时会阻塞。此时，如果调用线程池的shutdown方法，首先将线程池状态更新为**SHUTDOWN**，然后尝试获得Worker锁，如果可以获得，则可以证明其是空闲线程，然后发起**中断**；Worker线程发现线程池状态是**SHUTDOWN**并且队列没有任务，则结束线程运行
  - 如果无法获得锁，说明Worker线程正在处理任务。对于正在处理任务的Worker线程处理完成任务后，再次尝试获得任务发现线程池状态是**SHUTDOWN**并且队列中没有任务，则结束线程运行
  - Worker本身是一个AQS，被设计为排他锁，不可重入。获得锁，只是简单把state从0变为1；释放锁，把state改为0。
    - 设计为排他锁，当Worker线程获取到任务后，对Worker加锁，正在运行任务且**发生阻塞**时，如果主线程调用线程池的shutdown方法，中断空闲线程，主线程会尝试获得工作线程的锁，如果获取不到，说明正在处理任务不得中断，否则调用线程的中断方法。**也就是说，阻塞分两种情况，一种是任务前的阻塞（可被中断），如等待获取任务；另一种是任务中的阻塞（不可被中断）**。
    - 设计为不可重入，在任务处理过程中如果调用setCorePoolSize（beforeExecute），其可能会调用interruptIdleWorkers，这样有可能会中断正在运行的任务



### Callable/Future/FutureTask/CompletableFuture

- Callable可返回结果、可抛出异常的<font color=red>任务</font>
- Runnable没有返回结果、不会抛出异常的<font color=red>任务</font>。任务是由线程执行的基本单元
- Future接口，表示一个异步计算<font color=red>结果</font>，提供检查计算是否完成、取消计算任务、获取计算结果
- FutureTask<font color=red>可取消的异步计算任务</font>。本质是一个供线程执行的任务，  因为**实现了Runnable接口；同时，其还实现了Future接口**，因此可以异步获得计算结果
  - 被调用线程运行时，调用FutureTask的run方法，其委托调用Callable执行任务
  - 可以通过FutureTask异步获取任务执行结果
- CompletableFuture 异步、回调、组合



## 并发集合类

线程安全是写冲突和读写冲突导致的。最简单办法就是，读写都加锁。

- ArrayList 的方法都加上 synchronized -> Vector

- Collections.synchronizedList，强制将 List 的操作加上同步

- Arrays.asList，不允许添加删除，但是可以 set 替换元素

- Collections.unmodifiableList，不允许修改内容，包括添加、删除和修改



### CopyOnWriteArrayList

<font color=red>读写分离，最终一致。容忍一定读取数据的滞后情况，但可以保证正确性。</font>

- 无锁并发读
- 写加锁
  - 将原容器拷贝一份，写操作作用在新副本上，需要加锁（写互斥）。此过程若有读操作，则会作用在原容器上
  - 操作完成后，将原容器引用指向新副本。切换过程，用volatile保证切换过程对读线程立即可见



### ConcurrentHashMap

- Java 7

  分段锁，默认16个Segment，降低锁粒度。

  - 根据哈希码高sshift位决定Segment数组的index
  - 根据哈希码决定HashEntry数组的index

- Java 8

  为进一步提高并发性，摒弃了分段锁的方案，而是直接使用一个大的数组。在链表长度到8 & 数组长度到64时，使用红黑树。



### BlockingQueue

- ArrayBlockingQueue

  是 BlockingQueue 接口的有界队列实现类，底层采用**数组**来实现。ArrayBlockingQueue 一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞；尝试从一个空队列中取一个元素也会同样阻塞。

- LinkedBlockingQueue

  底层基于**单向链表**实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增大，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE。

- PriorityBlockingQueue

  是一个支持优先级的无界（长度不够会扩容）阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 `compareTo()` 方法来指定元素排序规则，或者初始化时通过构造器参数 `Comparator` 来指定排序规则。

- ConcurrentSkipListMap

  跳表实现



# AQS

AbstractQueuedSynchronizer 抽象队列同步器，多线程访问共享资源的框架。核心包括

- 独占锁
- 共享锁
- 支持响应中断、超时
- CLH队列



## 核心类和变量

### Node

CLH双向链表队列，Node为队列上的一个节点，每个请求共享资源的线程封装为一个节点。

| 方法和属性值        | 含义                              |
| :------------------ | :-------------------------------- |
| waitStatus          | 当前节点在队列中的状态            |
| thread              | 表示处于该节点的线程              |
| prev                | 前驱指针                          |
| predecessor（方法） | 返回前驱节点，没有的话抛出npe     |
| nextWaiter          | 指向下一个处于CONDITION状态的节点 |
| next                | 后继指针                          |

两种锁模式

| 模式      | 含义                           |
| :-------- | :----------------------------- |
| SHARED    | 表示线程以共享的模式等待锁     |
| EXCLUSIVE | 表示线程正在以独占的方式等待锁 |

waitStatus状态值

| 枚举      | 含义                                                         |
| :-------- | :----------------------------------------------------------- |
| RUNNING   | 为0，当一个Node被初始化的时候的默认值，表示当前Node绑定的线程正在运行中 |
| CANCELLED | 为1，被取消的，在等待队列中等待的线程超时或被中断，进入该状态的节点的将不再变化 |
| SIGNAL    | 为-1，当前节点在入队后、进入休眠状态前，应确保将其prev节点类型改为SIGNAL，以便后者取消或释放时将当前节点唤醒。 |
| CONDITION | 为-2，该节点处于条件队列中，当其他线程调用了Condition的signal()方法后，节点转移到AQS的等待队列中，特别要注意的是，条件队列和AQS的等待队列并不是一回事。 |
| PROPAGATE | 为-3，当前线程处在SHARED情况下，该字段才会使用               |



### state

修饰为volatile，表示共享资源当前的使用情况。



## 子类重写方法

自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-tryRelease。

| 方法名                                      | 描述                                                         |
| :------------------------------------------ | :----------------------------------------------------------- |
| protected boolean isHeldExclusively()       | 该线程是否正在独占资源。只有用到Condition才需要去实现它。    |
| protected boolean tryAcquire(int arg)       | 独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。 |
| protected boolean tryRelease(int arg)       | 独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。 |
| protected int tryAcquireShared(int arg)     | 共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 |
| protected boolean tryReleaseShared(int arg) | 共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。 |



## 独占锁流程分析

![concurrency_aqs_acquire_release](并发编程.assets/concurrency_aqs_acquire_release.png)



1. 客户端线程调用 `acquire` 获取锁
2. <font color=red>调用 `tryAcquire` 异步获取锁，此方法由AQS子类实现，CAS修改state状态。如果成功，更新exclusiveOwnerThread为当前线程，表示成功获取到锁</font>


3. 未获取到锁，调用 `addWaiter` 方法，创建<font color=red>绑定当前线程的Node节点</font>并**进入等待队列**

   - 首次入队，调用 `enq`，创建head节点，head和tail都指向这个节点；然后通过**自旋+CAS**的方式，将Node节点插入到队尾。注意，插入队尾的操作不是原子操作，在CAS前改变Node节点的前驱不会产生并发问题。
   - 如果队列有节点，则先通过CAS方式插入到队尾，如果并发失败，则调用 `enq` 通过自旋+CAS的方式将Node节点插入到队尾。

4. Node节点进入队列后获取锁

   - 如果他的前驱节点是head，说明他是队列中第一个等待执行的线程，尝试一次 `tryAcquire` 异步获取锁；如果成功获取到锁，把他设置为头节点
     -  `tryAcquire` 由AQS子类实现，根据方法签名可能会抛出运行时异常，所以此种情况调用 `cancelAcquire` 方法；<font color=red>产生的CANCELLED节点先断开next指针</font>
       - 如果是尾节点，waitStatus更新为CANCELLED，改变尾结点为前驱节点
       - 如果是中间节点，waitStatus更新为CANCELLED，保证前驱节点的waitStatus是SIGNAL
       - 如果是head的后继节点，waitStatus更新为CANCELLED，则从后向前找head后出现的第一个waitStatus<=0的节点，然后调用unpark唤醒线程
   - 如果不是第一个等待执行的节点，或者是第一个节点但获取锁失败（非公平锁被抢占），调用 `shouldParkAfterFailedAcquire` 判断获取锁失败后是否阻塞当前线程

     - 如果Node节点的前驱节点waitStatus是CANCELLED（1），则向前遍历前驱节点直到找到<0的节点，即非CANCELLED的节点，然后建立链接关系。<font color=red>断开prev指针</font>。对于CANCELLED节点失去引用会GC回收。自旋执行4
     - 如果Node节点的前驱节点waitStatus是RUNNING（0）、CONDITION（-2）、PROPAGATE（-3），则前驱节点的waitStatus更新为SIGNAL（-1）自旋执行4
     - 如果Node节点的前驱节点waitStatus是SIGNAL（-1）可以安全阻塞Node节点线程，向下执行5

5. 执行 `parkAndCheckInterrupt` 阻塞当前线程
   - `LockSupport.park` 申请许可，默认情况初始是0，因此阻塞当前线程；可以响应unpark和interrupt，从阻塞状态恢复，但不会抛出中断异常，只是记录在自旋等待过程中是否被中断过，继续执行4自旋获取锁
     - 如果成功获取到锁后，并在等待过程中断过，调用 `Thread.currentThread().interrupt()` 重新登记中断标识

6. 客户端线程调用 `release` 释放锁
7. <font color=red>调用 `tryRelease` 异步释放锁，此方法由AQS子类实现，CAS修改state状态。如果成功，唤醒队列中等待的线程节点；否则，需要继续释放持有的锁。</font>注意，修改状态前，必须要检查当前调用 `release` 方法的线程是否和持有锁的线程是同一个，不相同抛出IllegalMonitorStateException异常
8. 调用 `unparkSuccessor` 唤醒队列中等待的线程节点
   - 如果head的waitStatus=0，说明其后继节点正在运行中，不需要被唤醒
   - 如果head的waitStatus<0，更新waitStatus为0，其后继节点可以被唤醒运行，唤醒head的后继节点，执行4
     - 如果head的后继节点的waitStatus>0，说明已经被CANCELLED，则从后向前找head后出现的第一个waitStatus<=0的节点，然后调用unpark唤醒线程
     - 否则，head的后继节点正常阻塞，直接调用unpark唤醒线程



## ReentrantLock 分析

### lock获得锁

1. 客户端调用lock，ReentrantLock 委托给内部类Sync的lock，其是AbstractQueuedSynchronizer的子类，负责共享资源的同步
   - Sync是抽象类，有两个实现类分别是NonfairSync和FairSync，**默认是NonfairSync**
2. 委托给Sync的子类调用lock方法
   - 如果是NonfairSync，不管是否队列中有阻塞的线程，马上CAS尝试对资源上锁（0->1）。
     - 成功，设置当前线程持有锁
     - 不成功，执行AQS的acquire流程
   - 如果是FairSync，执行AQS的acquire流程
3. 异步获取锁调用子类的tryAcquire
   - 如果是NonfairSync，不管是否队列中有阻塞的线程，CAS尝试对资源上锁，其实现了可重入锁的机制，即累加state
   - 如果是FairSync，先判断队列中是否有阻塞的线程，如果有tryAcquire失败。否则，CAS尝试对资源上锁，其实现了可重入锁的机制，即累加state



### unlock释放锁

1. 客户端调用unlock，ReentrantLock 委托给内部类Sync的unlock，其未实现，直接调用AQS的release流程
2. 异步释放锁调用Sync的tryRelease，因为release不存在并发问题，所以直接对state减值（1->0），如果操作的线程不是持有锁的线程，则抛出异常。成功后，由AQS唤醒队列中的首个节点



### lockInterruptibly 获得锁

支持中断模式

1. 客户端调用lockInterruptibly，ReentrantLock 委托给内部类Sync的acquireInterruptibly，其未实现，直接调用AQS的acquireInterruptibly
   - 在尝试获得锁前，支持中断，抛出InterruptedException异常
   - 在未获得锁，进入队列阻塞后，支持中断，抛出InterruptedException异常；同时，会先将队列中的节点waitStatus设置为CANCELLED。
     - 与普通acquire的区别是，普通acquire进入队列阻塞后，如果被中断，并不会抛出InterruptedException异常，只是记录中断标志，被唤醒后仍将持续尝试获得锁

